{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8a3cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6134f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "import random\n",
    "\n",
    "fake = Faker()\n",
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "six_months = date.today() - relativedelta(months=+6)\n",
    "three_months = date.today() - relativedelta(months=+3)\n",
    "months = [three_months, six_months]\n",
    "\n",
    "# Generate demographic and personal information\n",
    "def generate_customer_data():\n",
    "    age = random.randint(20, 70)\n",
    "    gender = random.choice(['Male', 'Female'])\n",
    "    marital_status = random.choice(['Single', 'Married', 'Divorced', 'Widowed'])\n",
    "    income_level = random.choice(['Low', 'Medium', 'High'])\n",
    "    education = random.choice(['High School', 'College', 'University'])\n",
    "    occupation = fake.job()\n",
    "    residential_status = random.choice(['Owns house', 'Rents', 'Living with parents'])\n",
    "    dependents = random.randint(0, 5),  # Number of dependents\n",
    "    debt_to_income = round(random.uniform(0.1, 0.5), 2),  # Debt-to-income ratio\n",
    "    credit_bureau = random.randint(760, 850)\n",
    "\n",
    "    return {\n",
    "        'Age': age,\n",
    "        'Gender': gender,\n",
    "        'Marital Status': marital_status,\n",
    "        'Income Level': income_level,\n",
    "        'Education': education,\n",
    "        'Occupation': occupation,\n",
    "        'Residential Status': residential_status,\n",
    "        'Dependents': dependents,\n",
    "        'Debt-to-Income': debt_to_income,\n",
    "        'Credit_Bureau': credit_bureau\n",
    "    }\n",
    "\n",
    "# Function to generate bureau product inquiries\n",
    "def generate_inquiries(last_months):\n",
    "    inquiries = []\n",
    "    today = fake.date_this_month()\n",
    "\n",
    "    # Generate inquiries for the last `last_months` period\n",
    "    for _ in range(random.randint(1, 5)):  # Random number of inquiries\n",
    "        inquiry_date = fake.date_between(start_date=last_months, end_date=today)\n",
    "        product_type = random.choice(['Personal Loan', 'Credit Card', 'Mortgage'])\n",
    "        inquiries.append({'product_name': product_type, 'date': inquiry_date})\n",
    "\n",
    "    return inquiries if inquiries else []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f637f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate dataset\n",
    "def generate_dataset(num_rows,months):\n",
    "    data_rows = []\n",
    "\n",
    "    for _ in range(num_rows):\n",
    "        customer_data = generate_customer_data()\n",
    "        last_3_months_inquiries = generate_inquiries(months[0])\n",
    "        last_6_months_inquiries = generate_inquiries(months[1])\n",
    "\n",
    "        # Initialize columns for each product type\n",
    "        customer_row = {\n",
    "            'Customer ID': fake.uuid4(),\n",
    "            'Age': customer_data['Age'],\n",
    "            'Gender': customer_data['Gender'],\n",
    "            'Marital Status': customer_data['Marital Status'],\n",
    "            'Income Level': customer_data['Income Level'],\n",
    "            'Education': customer_data['Education'],\n",
    "            'Occupation': customer_data['Occupation'],\n",
    "            'Residential Status': customer_data['Residential Status'],\n",
    "            'Dependents': customer_data['Dependents'],\n",
    "            'Debt-to-Income': customer_data['Debt-to-Income'],\n",
    "            'Credit_Bureau': customer_data['Credit_Bureau']\n",
    "        }\n",
    "\n",
    "        # Process last 3 months inquiries\n",
    "        for product_type in ['Personal Loan', 'Credit Card', 'Mortgage']:\n",
    "            inq_in_last_3_months = any(inq['product_name'] == product_type for inq in last_3_months_inquiries)\n",
    "            customer_row[f'last_3months_{product_type.replace(\" \", \"_\").lower()}_inq'] = inq_in_last_3_months\n",
    "\n",
    "        # Process last 6 months inquiries\n",
    "        for product_type in ['Personal Loan', 'Credit Card', 'Mortgage']:\n",
    "            inq_in_last_6_months = any(inq['product_name'] == product_type for inq in last_6_months_inquiries)\n",
    "            customer_row[f'last_6months_{product_type.replace(\" \", \"_\").lower()}_inq'] = inq_in_last_6_months\n",
    "\n",
    "        data_rows.append(customer_row)\n",
    "\n",
    "    return data_rows\n",
    "\n",
    "# Example usage to generate 50 rows of data\n",
    "dataset = generate_dataset(50, months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a3251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "df = pd.DataFrame(dataset)\n",
    "df.to_csv(\"products_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c069db73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da7413e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8b3b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content'] = [f\"Based on the following customer data: {data}, suggest suitable banking lending products.\" for data in dataset]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b4c9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcd74e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain langchain-community langchain-core transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6d26eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "\n",
    "# Prepare documents for LangChain\n",
    "documents = []\n",
    "for _, row in df.iterrows():\n",
    "    documents.append(Document(page_content=row[\"content\"], metadata={\"class\": row[\"Age\"]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410011f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence-transformers==2.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec80dab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7398865d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show huggingface_hub sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723bffa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8454c14d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "hg_embeddings = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102d5df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "persist_directory = '/Users/varunv/Desktop/GenFinRecAI/'\n",
    "\n",
    "langchain_chroma = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    collection_name=\"recommendation_engine\",\n",
    "    embedding=hg_embeddings,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bcbb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall torch -y\n",
    "!pip install torch --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10fee67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(\"MPS available:\", torch.backends.mps.is_available())\n",
    "print(\"MPS built:\", torch.backends.mps.is_built())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43007559",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import cuda, bfloat16\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "from time import time\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "model_id = 'HuggingFaceH4/zephyr-7b-beta'\n",
    "\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "\n",
    "# set quantization configuration to load large model with less GPU memory\n",
    "# this requires the `bitsandbytes` library\n",
    "bnb_config = transformers.BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=bfloat16\n",
    ")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663df3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f92d40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "   model_id,\n",
    "    trust_remote_code=True,\n",
    "    max_new_tokens=1024\n",
    ")\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    config=model_config,\n",
    "    torch_dtype=torch.float16,  # Use float16 for memory efficiency\n",
    "    device_map=\"auto\" ,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b48c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the query pipeline with increased max_length\n",
    "query_pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.float16,\n",
    "    max_length=6000,  # Increase max_length\n",
    "    max_new_tokens=500,  # Control the number of new tokens generated\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b69bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b69dadb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "def colorize_text(text):\n",
    "    for word, color in zip([\"Reasoning\", \"Question\", \"Answer\", \"Total time\"], [\"blue\", \"red\", \"green\", \"magenta\"]):\n",
    "        text = text.replace(f\"{word}:\", f\"\\n\\n**<font color='{color}'>{word}:</font>**\")\n",
    "    return text\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=query_pipeline)\n",
    "\n",
    "question = \"What is Recommendation Engie and How it used in Finance Domain?\"\n",
    "response = llm(prompt=question)\n",
    "\n",
    "full_response =  f\"Question: {question}\\nAnswer: {response}\"\n",
    "display(Markdown(colorize_text(full_response)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36db1f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
